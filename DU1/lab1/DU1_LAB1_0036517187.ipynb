{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nvtp-v5Zenor"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 data.py"
      ],
      "metadata": {
        "id": "BEyldC-EKjX2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 fcann2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnIn2gsyLCtw",
        "outputId": "7a44b192-aa61-4ffc-a64b-e82031276250"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss 6.213158795908594\n",
            "iteration 1000: loss 0.43680931078742025\n",
            "iteration 2000: loss 0.3627567122962079\n",
            "iteration 3000: loss 0.3219699080022129\n",
            "iteration 4000: loss 0.30594145811860385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 pt_linreg.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2rwWW8gM0ZG",
        "outputId": "15f45d45-77d0-4d9c-852e-9efb71c60666"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, loss:8.269914627075195, Y_:tensor([0.7923, 1.5844], grad_fn=<AddBackward0>)\n",
            "a:tensor([1.6960], requires_grad=True), a_grad:tensor([-9.0388]), a_grad_manual: -9.0388\n",
            " b:tensor([0.5626], requires_grad=True), b_grad:tensor([-5.6232]), b_grad_manual: -5.6232\n",
            "step: 1, loss:0.8213987350463867, Y_:tensor([2.2585, 3.9545], grad_fn=<AddBackward0>)\n",
            "a:tensor([1.9792], requires_grad=True), a_grad:tensor([-2.8324]), a_grad_manual: -2.8324\n",
            " b:tensor([0.7413], requires_grad=True), b_grad:tensor([-1.7869]), b_grad_manual: -1.7869\n",
            "step: 2, loss:0.08415773510932922, Y_:tensor([2.7205, 4.6997], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0672], requires_grad=True), a_grad:tensor([-0.8801]), a_grad_manual: -0.8801\n",
            " b:tensor([0.7992], requires_grad=True), b_grad:tensor([-0.5798]), b_grad_manual: -0.5798\n",
            "step: 3, loss:0.011112354695796967, Y_:tensor([2.8665, 4.9337], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0938], requires_grad=True), a_grad:tensor([-0.2661]), a_grad_manual: -0.2661\n",
            " b:tensor([0.8192], requires_grad=True), b_grad:tensor([-0.1998]), b_grad_manual: -0.1998\n",
            "step: 4, loss:0.0038026715628802776, Y_:tensor([2.9131, 5.0069], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.1012], requires_grad=True), a_grad:tensor([-0.0731]), a_grad_manual: -0.0731\n",
            " b:tensor([0.8272], requires_grad=True), b_grad:tensor([-0.0800]), b_grad_manual: -0.0800\n",
            "step: 5, loss:0.003000960685312748, Y_:tensor([2.9284, 5.0295], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.1024], requires_grad=True), a_grad:tensor([-0.0125]), a_grad_manual: -0.0125\n",
            " b:tensor([0.8314], requires_grad=True), b_grad:tensor([-0.0421]), b_grad_manual: -0.0421\n",
            "step: 6, loss:0.002845587907359004, Y_:tensor([2.9338, 5.0363], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.1018], requires_grad=True), a_grad:tensor([0.0064]), a_grad_manual: 0.0064\n",
            " b:tensor([0.8344], requires_grad=True), b_grad:tensor([-0.0299]), b_grad_manual: -0.0299\n",
            "step: 7, loss:0.0027563890907913446, Y_:tensor([2.9362, 5.0380], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.1006], requires_grad=True), a_grad:tensor([0.0121]), a_grad_manual: 0.0121\n",
            " b:tensor([0.8370], requires_grad=True), b_grad:tensor([-0.0258]), b_grad_manual: -0.0258\n",
            "step: 8, loss:0.002675882773473859, Y_:tensor([2.9376, 5.0381], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0992], requires_grad=True), a_grad:tensor([0.0138]), a_grad_manual: 0.0138\n",
            " b:tensor([0.8394], requires_grad=True), b_grad:tensor([-0.0243]), b_grad_manual: -0.0243\n",
            "step: 9, loss:0.0025982954539358616, Y_:tensor([2.9386, 5.0378], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0978], requires_grad=True), a_grad:tensor([0.0142]), a_grad_manual: 0.0142\n",
            " b:tensor([0.8418], requires_grad=True), b_grad:tensor([-0.0236]), b_grad_manual: -0.0236\n",
            "step: 10, loss:0.002523015718907118, Y_:tensor([2.9396, 5.0373], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0963], requires_grad=True), a_grad:tensor([0.0142]), a_grad_manual: 0.0142\n",
            " b:tensor([0.8441], requires_grad=True), b_grad:tensor([-0.0231]), b_grad_manual: -0.0231\n",
            "step: 11, loss:0.0024499408900737762, Y_:tensor([2.9404, 5.0368], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0949], requires_grad=True), a_grad:tensor([0.0140]), a_grad_manual: 0.0140\n",
            " b:tensor([0.8464], requires_grad=True), b_grad:tensor([-0.0228]), b_grad_manual: -0.0228\n",
            "step: 12, loss:0.0023789783008396626, Y_:tensor([2.9413, 5.0363], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0936], requires_grad=True), a_grad:tensor([0.0138]), a_grad_manual: 0.0138\n",
            " b:tensor([0.8486], requires_grad=True), b_grad:tensor([-0.0224]), b_grad_manual: -0.0224\n",
            "step: 13, loss:0.0023100741673260927, Y_:tensor([2.9422, 5.0357], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0922], requires_grad=True), a_grad:tensor([0.0136]), a_grad_manual: 0.0136\n",
            " b:tensor([0.8508], requires_grad=True), b_grad:tensor([-0.0221]), b_grad_manual: -0.0221\n",
            "step: 14, loss:0.002243141643702984, Y_:tensor([2.9430, 5.0352], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0908], requires_grad=True), a_grad:tensor([0.0134]), a_grad_manual: 0.0134\n",
            " b:tensor([0.8530], requires_grad=True), b_grad:tensor([-0.0218]), b_grad_manual: -0.0218\n",
            "step: 15, loss:0.0021781667601317167, Y_:tensor([2.9439, 5.0347], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0895], requires_grad=True), a_grad:tensor([0.0133]), a_grad_manual: 0.0133\n",
            " b:tensor([0.8552], requires_grad=True), b_grad:tensor([-0.0214]), b_grad_manual: -0.0214\n",
            "step: 16, loss:0.00211508059874177, Y_:tensor([2.9447, 5.0342], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0882], requires_grad=True), a_grad:tensor([0.0131]), a_grad_manual: 0.0131\n",
            " b:tensor([0.8573], requires_grad=True), b_grad:tensor([-0.0211]), b_grad_manual: -0.0211\n",
            "step: 17, loss:0.0020538121461868286, Y_:tensor([2.9455, 5.0337], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0869], requires_grad=True), a_grad:tensor([0.0129]), a_grad_manual: 0.0129\n",
            " b:tensor([0.8594], requires_grad=True), b_grad:tensor([-0.0208]), b_grad_manual: -0.0208\n",
            "step: 18, loss:0.0019943220540881157, Y_:tensor([2.9463, 5.0332], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0857], requires_grad=True), a_grad:tensor([0.0127]), a_grad_manual: 0.0127\n",
            " b:tensor([0.8614], requires_grad=True), b_grad:tensor([-0.0205]), b_grad_manual: -0.0205\n",
            "step: 19, loss:0.0019365557236596942, Y_:tensor([2.9471, 5.0327], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0844], requires_grad=True), a_grad:tensor([0.0125]), a_grad_manual: 0.0125\n",
            " b:tensor([0.8634], requires_grad=True), b_grad:tensor([-0.0202]), b_grad_manual: -0.0202\n",
            "step: 20, loss:0.00188045937102288, Y_:tensor([2.9478, 5.0322], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0832], requires_grad=True), a_grad:tensor([0.0123]), a_grad_manual: 0.0123\n",
            " b:tensor([0.8654], requires_grad=True), b_grad:tensor([-0.0199]), b_grad_manual: -0.0199\n",
            "step: 21, loss:0.001825996907427907, Y_:tensor([2.9486, 5.0318], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0820], requires_grad=True), a_grad:tensor([0.0121]), a_grad_manual: 0.0121\n",
            " b:tensor([0.8674], requires_grad=True), b_grad:tensor([-0.0196]), b_grad_manual: -0.0196\n",
            "step: 22, loss:0.001773102325387299, Y_:tensor([2.9493, 5.0313], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0808], requires_grad=True), a_grad:tensor([0.0120]), a_grad_manual: 0.0120\n",
            " b:tensor([0.8693], requires_grad=True), b_grad:tensor([-0.0193]), b_grad_manual: -0.0193\n",
            "step: 23, loss:0.0017217237036675215, Y_:tensor([2.9501, 5.0308], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0796], requires_grad=True), a_grad:tensor([0.0118]), a_grad_manual: 0.0118\n",
            " b:tensor([0.8712], requires_grad=True), b_grad:tensor([-0.0191]), b_grad_manual: -0.0191\n",
            "step: 24, loss:0.0016718599945306778, Y_:tensor([2.9508, 5.0304], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0784], requires_grad=True), a_grad:tensor([0.0116]), a_grad_manual: 0.0116\n",
            " b:tensor([0.8731], requires_grad=True), b_grad:tensor([-0.0188]), b_grad_manual: -0.0188\n",
            "step: 25, loss:0.001623423071578145, Y_:tensor([2.9515, 5.0300], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0773], requires_grad=True), a_grad:tensor([0.0114]), a_grad_manual: 0.0114\n",
            " b:tensor([0.8750], requires_grad=True), b_grad:tensor([-0.0185]), b_grad_manual: -0.0185\n",
            "step: 26, loss:0.001576407696120441, Y_:tensor([2.9522, 5.0295], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0762], requires_grad=True), a_grad:tensor([0.0113]), a_grad_manual: 0.0113\n",
            " b:tensor([0.8768], requires_grad=True), b_grad:tensor([-0.0182]), b_grad_manual: -0.0182\n",
            "step: 27, loss:0.0015307433204725385, Y_:tensor([2.9529, 5.0291], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0750], requires_grad=True), a_grad:tensor([0.0111]), a_grad_manual: 0.0111\n",
            " b:tensor([0.8786], requires_grad=True), b_grad:tensor([-0.0180]), b_grad_manual: -0.0180\n",
            "step: 28, loss:0.0014863945543766022, Y_:tensor([2.9536, 5.0287], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0740], requires_grad=True), a_grad:tensor([0.0109]), a_grad_manual: 0.0109\n",
            " b:tensor([0.8803], requires_grad=True), b_grad:tensor([-0.0177]), b_grad_manual: -0.0177\n",
            "step: 29, loss:0.0014433548785746098, Y_:tensor([2.9543, 5.0282], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0729], requires_grad=True), a_grad:tensor([0.0108]), a_grad_manual: 0.0108\n",
            " b:tensor([0.8821], requires_grad=True), b_grad:tensor([-0.0175]), b_grad_manual: -0.0175\n",
            "step: 30, loss:0.001401544432155788, Y_:tensor([2.9550, 5.0278], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0718], requires_grad=True), a_grad:tensor([0.0106]), a_grad_manual: 0.0106\n",
            " b:tensor([0.8838], requires_grad=True), b_grad:tensor([-0.0172]), b_grad_manual: -0.0172\n",
            "step: 31, loss:0.0013609309680759907, Y_:tensor([2.9556, 5.0274], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0708], requires_grad=True), a_grad:tensor([0.0105]), a_grad_manual: 0.0105\n",
            " b:tensor([0.8855], requires_grad=True), b_grad:tensor([-0.0170]), b_grad_manual: -0.0170\n",
            "step: 32, loss:0.0013215098297223449, Y_:tensor([2.9563, 5.0270], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0697], requires_grad=True), a_grad:tensor([0.0103]), a_grad_manual: 0.0103\n",
            " b:tensor([0.8872], requires_grad=True), b_grad:tensor([-0.0167]), b_grad_manual: -0.0167\n",
            "step: 33, loss:0.0012832313077524304, Y_:tensor([2.9569, 5.0266], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0687], requires_grad=True), a_grad:tensor([0.0102]), a_grad_manual: 0.0102\n",
            " b:tensor([0.8888], requires_grad=True), b_grad:tensor([-0.0165]), b_grad_manual: -0.0165\n",
            "step: 34, loss:0.0012460602447390556, Y_:tensor([2.9575, 5.0262], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0677], requires_grad=True), a_grad:tensor([0.0100]), a_grad_manual: 0.0100\n",
            " b:tensor([0.8904], requires_grad=True), b_grad:tensor([-0.0162]), b_grad_manual: -0.0162\n",
            "step: 35, loss:0.0012099725427106023, Y_:tensor([2.9582, 5.0259], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0667], requires_grad=True), a_grad:tensor([0.0099]), a_grad_manual: 0.0099\n",
            " b:tensor([0.8920], requires_grad=True), b_grad:tensor([-0.0160]), b_grad_manual: -0.0160\n",
            "step: 36, loss:0.0011749246623367071, Y_:tensor([2.9588, 5.0255], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0657], requires_grad=True), a_grad:tensor([0.0097]), a_grad_manual: 0.0097\n",
            " b:tensor([0.8936], requires_grad=True), b_grad:tensor([-0.0158]), b_grad_manual: -0.0158\n",
            "step: 37, loss:0.0011408916907384992, Y_:tensor([2.9594, 5.0251], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0648], requires_grad=True), a_grad:tensor([0.0096]), a_grad_manual: 0.0096\n",
            " b:tensor([0.8952], requires_grad=True), b_grad:tensor([-0.0155]), b_grad_manual: -0.0155\n",
            "step: 38, loss:0.0011078440584242344, Y_:tensor([2.9600, 5.0247], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0638], requires_grad=True), a_grad:tensor([0.0095]), a_grad_manual: 0.0095\n",
            " b:tensor([0.8967], requires_grad=True), b_grad:tensor([-0.0153]), b_grad_manual: -0.0153\n",
            "step: 39, loss:0.0010757464915513992, Y_:tensor([2.9605, 5.0244], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0629], requires_grad=True), a_grad:tensor([0.0093]), a_grad_manual: 0.0093\n",
            " b:tensor([0.8982], requires_grad=True), b_grad:tensor([-0.0151]), b_grad_manual: -0.0151\n",
            "step: 40, loss:0.0010445918887853622, Y_:tensor([2.9611, 5.0240], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0620], requires_grad=True), a_grad:tensor([0.0092]), a_grad_manual: 0.0092\n",
            " b:tensor([0.8997], requires_grad=True), b_grad:tensor([-0.0149]), b_grad_manual: -0.0149\n",
            "step: 41, loss:0.0010143297258764505, Y_:tensor([2.9617, 5.0237], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0611], requires_grad=True), a_grad:tensor([0.0090]), a_grad_manual: 0.0090\n",
            " b:tensor([0.9012], requires_grad=True), b_grad:tensor([-0.0146]), b_grad_manual: -0.0146\n",
            "step: 42, loss:0.0009849477792158723, Y_:tensor([2.9622, 5.0233], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0602], requires_grad=True), a_grad:tensor([0.0089]), a_grad_manual: 0.0089\n",
            " b:tensor([0.9026], requires_grad=True), b_grad:tensor([-0.0144]), b_grad_manual: -0.0144\n",
            "step: 43, loss:0.0009564108913764358, Y_:tensor([2.9628, 5.0230], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0593], requires_grad=True), a_grad:tensor([0.0088]), a_grad_manual: 0.0088\n",
            " b:tensor([0.9040], requires_grad=True), b_grad:tensor([-0.0142]), b_grad_manual: -0.0142\n",
            "step: 44, loss:0.0009287181892432272, Y_:tensor([2.9633, 5.0227], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0585], requires_grad=True), a_grad:tensor([0.0087]), a_grad_manual: 0.0087\n",
            " b:tensor([0.9054], requires_grad=True), b_grad:tensor([-0.0140]), b_grad_manual: -0.0140\n",
            "step: 45, loss:0.0009018037235364318, Y_:tensor([2.9639, 5.0223], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0576], requires_grad=True), a_grad:tensor([0.0085]), a_grad_manual: 0.0085\n",
            " b:tensor([0.9068], requires_grad=True), b_grad:tensor([-0.0138]), b_grad_manual: -0.0138\n",
            "step: 46, loss:0.000875680532772094, Y_:tensor([2.9644, 5.0220], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0568], requires_grad=True), a_grad:tensor([0.0084]), a_grad_manual: 0.0084\n",
            " b:tensor([0.9082], requires_grad=True), b_grad:tensor([-0.0136]), b_grad_manual: -0.0136\n",
            "step: 47, loss:0.0008503205608576536, Y_:tensor([2.9649, 5.0217], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0559], requires_grad=True), a_grad:tensor([0.0083]), a_grad_manual: 0.0083\n",
            " b:tensor([0.9095], requires_grad=True), b_grad:tensor([-0.0134]), b_grad_manual: -0.0134\n",
            "step: 48, loss:0.0008256823057308793, Y_:tensor([2.9654, 5.0214], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0551], requires_grad=True), a_grad:tensor([0.0082]), a_grad_manual: 0.0082\n",
            " b:tensor([0.9108], requires_grad=True), b_grad:tensor([-0.0132]), b_grad_manual: -0.0132\n",
            "step: 49, loss:0.0008017726941034198, Y_:tensor([2.9659, 5.0211], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0543], requires_grad=True), a_grad:tensor([0.0080]), a_grad_manual: 0.0080\n",
            " b:tensor([0.9121], requires_grad=True), b_grad:tensor([-0.0130]), b_grad_manual: -0.0130\n",
            "step: 50, loss:0.0007785453926771879, Y_:tensor([2.9664, 5.0207], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0535], requires_grad=True), a_grad:tensor([0.0079]), a_grad_manual: 0.0079\n",
            " b:tensor([0.9134], requires_grad=True), b_grad:tensor([-0.0128]), b_grad_manual: -0.0128\n",
            "step: 51, loss:0.0007559916703030467, Y_:tensor([2.9669, 5.0204], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0527], requires_grad=True), a_grad:tensor([0.0078]), a_grad_manual: 0.0078\n",
            " b:tensor([0.9147], requires_grad=True), b_grad:tensor([-0.0126]), b_grad_manual: -0.0126\n",
            "step: 52, loss:0.0007340985466726124, Y_:tensor([2.9674, 5.0201], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0520], requires_grad=True), a_grad:tensor([0.0077]), a_grad_manual: 0.0077\n",
            " b:tensor([0.9159], requires_grad=True), b_grad:tensor([-0.0124]), b_grad_manual: -0.0124\n",
            "step: 53, loss:0.0007128343568183482, Y_:tensor([2.9679, 5.0199], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0512], requires_grad=True), a_grad:tensor([0.0076]), a_grad_manual: 0.0076\n",
            " b:tensor([0.9171], requires_grad=True), b_grad:tensor([-0.0123]), b_grad_manual: -0.0123\n",
            "step: 54, loss:0.0006921760505065322, Y_:tensor([2.9683, 5.0196], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0505], requires_grad=True), a_grad:tensor([0.0075]), a_grad_manual: 0.0075\n",
            " b:tensor([0.9183], requires_grad=True), b_grad:tensor([-0.0121]), b_grad_manual: -0.0121\n",
            "step: 55, loss:0.0006721365498378873, Y_:tensor([2.9688, 5.0193], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0497], requires_grad=True), a_grad:tensor([0.0074]), a_grad_manual: 0.0074\n",
            " b:tensor([0.9195], requires_grad=True), b_grad:tensor([-0.0119]), b_grad_manual: -0.0119\n",
            "step: 56, loss:0.0006526689394377172, Y_:tensor([2.9693, 5.0190], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0490], requires_grad=True), a_grad:tensor([0.0073]), a_grad_manual: 0.0073\n",
            " b:tensor([0.9207], requires_grad=True), b_grad:tensor([-0.0117]), b_grad_manual: -0.0117\n",
            "step: 57, loss:0.0006337626837193966, Y_:tensor([2.9697, 5.0187], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0483], requires_grad=True), a_grad:tensor([0.0071]), a_grad_manual: 0.0071\n",
            " b:tensor([0.9219], requires_grad=True), b_grad:tensor([-0.0116]), b_grad_manual: -0.0116\n",
            "step: 58, loss:0.0006154038710519671, Y_:tensor([2.9702, 5.0184], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0476], requires_grad=True), a_grad:tensor([0.0070]), a_grad_manual: 0.0070\n",
            " b:tensor([0.9230], requires_grad=True), b_grad:tensor([-0.0114]), b_grad_manual: -0.0114\n",
            "step: 59, loss:0.0005975735257379711, Y_:tensor([2.9706, 5.0182], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0469], requires_grad=True), a_grad:tensor([0.0069]), a_grad_manual: 0.0069\n",
            " b:tensor([0.9241], requires_grad=True), b_grad:tensor([-0.0112]), b_grad_manual: -0.0112\n",
            "step: 60, loss:0.0005802633240818977, Y_:tensor([2.9710, 5.0179], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0462], requires_grad=True), a_grad:tensor([0.0068]), a_grad_manual: 0.0068\n",
            " b:tensor([0.9252], requires_grad=True), b_grad:tensor([-0.0111]), b_grad_manual: -0.0111\n",
            "step: 61, loss:0.0005634487024508417, Y_:tensor([2.9714, 5.0176], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0455], requires_grad=True), a_grad:tensor([0.0067]), a_grad_manual: 0.0067\n",
            " b:tensor([0.9263], requires_grad=True), b_grad:tensor([-0.0109]), b_grad_manual: -0.0109\n",
            "step: 62, loss:0.0005471318727359176, Y_:tensor([2.9719, 5.0174], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0449], requires_grad=True), a_grad:tensor([0.0066]), a_grad_manual: 0.0066\n",
            " b:tensor([0.9274], requires_grad=True), b_grad:tensor([-0.0107]), b_grad_manual: -0.0107\n",
            "step: 63, loss:0.0005312839057296515, Y_:tensor([2.9723, 5.0171], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0442], requires_grad=True), a_grad:tensor([0.0065]), a_grad_manual: 0.0065\n",
            " b:tensor([0.9285], requires_grad=True), b_grad:tensor([-0.0106]), b_grad_manual: -0.0106\n",
            "step: 64, loss:0.0005158944986760616, Y_:tensor([2.9727, 5.0169], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0436], requires_grad=True), a_grad:tensor([0.0065]), a_grad_manual: 0.0065\n",
            " b:tensor([0.9295], requires_grad=True), b_grad:tensor([-0.0104]), b_grad_manual: -0.0104\n",
            "step: 65, loss:0.0005009567830711603, Y_:tensor([2.9731, 5.0166], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0429], requires_grad=True), a_grad:tensor([0.0064]), a_grad_manual: 0.0064\n",
            " b:tensor([0.9305], requires_grad=True), b_grad:tensor([-0.0103]), b_grad_manual: -0.0103\n",
            "step: 66, loss:0.00048643717309460044, Y_:tensor([2.9735, 5.0164], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0423], requires_grad=True), a_grad:tensor([0.0063]), a_grad_manual: 0.0063\n",
            " b:tensor([0.9315], requires_grad=True), b_grad:tensor([-0.0101]), b_grad_manual: -0.0101\n",
            "step: 67, loss:0.0004723500751424581, Y_:tensor([2.9739, 5.0162], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0417], requires_grad=True), a_grad:tensor([0.0062]), a_grad_manual: 0.0062\n",
            " b:tensor([0.9325], requires_grad=True), b_grad:tensor([-0.0100]), b_grad_manual: -0.0100\n",
            "step: 68, loss:0.00045866903383284807, Y_:tensor([2.9742, 5.0159], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0411], requires_grad=True), a_grad:tensor([0.0061]), a_grad_manual: 0.0061\n",
            " b:tensor([0.9335], requires_grad=True), b_grad:tensor([-0.0098]), b_grad_manual: -0.0098\n",
            "step: 69, loss:0.0004453820292837918, Y_:tensor([2.9746, 5.0157], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0405], requires_grad=True), a_grad:tensor([0.0060]), a_grad_manual: 0.0060\n",
            " b:tensor([0.9345], requires_grad=True), b_grad:tensor([-0.0097]), b_grad_manual: -0.0097\n",
            "step: 70, loss:0.0004324851033743471, Y_:tensor([2.9750, 5.0155], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0399], requires_grad=True), a_grad:tensor([0.0059]), a_grad_manual: 0.0059\n",
            " b:tensor([0.9355], requires_grad=True), b_grad:tensor([-0.0096]), b_grad_manual: -0.0096\n",
            "step: 71, loss:0.00041995776700787246, Y_:tensor([2.9753, 5.0152], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0393], requires_grad=True), a_grad:tensor([0.0058]), a_grad_manual: 0.0058\n",
            " b:tensor([0.9364], requires_grad=True), b_grad:tensor([-0.0094]), b_grad_manual: -0.0094\n",
            "step: 72, loss:0.00040778491529636085, Y_:tensor([2.9757, 5.0150], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0387], requires_grad=True), a_grad:tensor([0.0057]), a_grad_manual: 0.0057\n",
            " b:tensor([0.9373], requires_grad=True), b_grad:tensor([-0.0093]), b_grad_manual: -0.0093\n",
            "step: 73, loss:0.00039597306749783456, Y_:tensor([2.9761, 5.0148], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0382], requires_grad=True), a_grad:tensor([0.0057]), a_grad_manual: 0.0057\n",
            " b:tensor([0.9382], requires_grad=True), b_grad:tensor([-0.0091]), b_grad_manual: -0.0091\n",
            "step: 74, loss:0.00038450717693194747, Y_:tensor([2.9764, 5.0146], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0376], requires_grad=True), a_grad:tensor([0.0056]), a_grad_manual: 0.0056\n",
            " b:tensor([0.9391], requires_grad=True), b_grad:tensor([-0.0090]), b_grad_manual: -0.0090\n",
            "step: 75, loss:0.0003733659104909748, Y_:tensor([2.9768, 5.0144], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0371], requires_grad=True), a_grad:tensor([0.0055]), a_grad_manual: 0.0055\n",
            " b:tensor([0.9400], requires_grad=True), b_grad:tensor([-0.0089]), b_grad_manual: -0.0089\n",
            "step: 76, loss:0.0003625584067776799, Y_:tensor([2.9771, 5.0142], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0365], requires_grad=True), a_grad:tensor([0.0054]), a_grad_manual: 0.0054\n",
            " b:tensor([0.9409], requires_grad=True), b_grad:tensor([-0.0087]), b_grad_manual: -0.0087\n",
            "step: 77, loss:0.00035204796586185694, Y_:tensor([2.9774, 5.0139], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0360], requires_grad=True), a_grad:tensor([0.0053]), a_grad_manual: 0.0053\n",
            " b:tensor([0.9418], requires_grad=True), b_grad:tensor([-0.0086]), b_grad_manual: -0.0086\n",
            "step: 78, loss:0.0003418571432121098, Y_:tensor([2.9778, 5.0137], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0355], requires_grad=True), a_grad:tensor([0.0053]), a_grad_manual: 0.0053\n",
            " b:tensor([0.9426], requires_grad=True), b_grad:tensor([-0.0085]), b_grad_manual: -0.0085\n",
            "step: 79, loss:0.0003319475508760661, Y_:tensor([2.9781, 5.0135], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0349], requires_grad=True), a_grad:tensor([0.0052]), a_grad_manual: 0.0052\n",
            " b:tensor([0.9435], requires_grad=True), b_grad:tensor([-0.0084]), b_grad_manual: -0.0084\n",
            "step: 80, loss:0.0003223364183213562, Y_:tensor([2.9784, 5.0133], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0344], requires_grad=True), a_grad:tensor([0.0051]), a_grad_manual: 0.0051\n",
            " b:tensor([0.9443], requires_grad=True), b_grad:tensor([-0.0082]), b_grad_manual: -0.0082\n",
            "step: 81, loss:0.0003129942051600665, Y_:tensor([2.9787, 5.0132], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0339], requires_grad=True), a_grad:tensor([0.0050]), a_grad_manual: 0.0050\n",
            " b:tensor([0.9451], requires_grad=True), b_grad:tensor([-0.0081]), b_grad_manual: -0.0081\n",
            "step: 82, loss:0.0003039326402358711, Y_:tensor([2.9790, 5.0130], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0334], requires_grad=True), a_grad:tensor([0.0050]), a_grad_manual: 0.0050\n",
            " b:tensor([0.9459], requires_grad=True), b_grad:tensor([-0.0080]), b_grad_manual: -0.0080\n",
            "step: 83, loss:0.00029512823675759137, Y_:tensor([2.9793, 5.0128], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0330], requires_grad=True), a_grad:tensor([0.0049]), a_grad_manual: 0.0049\n",
            " b:tensor([0.9467], requires_grad=True), b_grad:tensor([-0.0079]), b_grad_manual: -0.0079\n",
            "step: 84, loss:0.00028658262453973293, Y_:tensor([2.9796, 5.0126], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0325], requires_grad=True), a_grad:tensor([0.0048]), a_grad_manual: 0.0048\n",
            " b:tensor([0.9475], requires_grad=True), b_grad:tensor([-0.0078]), b_grad_manual: -0.0078\n",
            "step: 85, loss:0.00027827711892314255, Y_:tensor([2.9799, 5.0124], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0320], requires_grad=True), a_grad:tensor([0.0047]), a_grad_manual: 0.0047\n",
            " b:tensor([0.9482], requires_grad=True), b_grad:tensor([-0.0077]), b_grad_manual: -0.0077\n",
            "step: 86, loss:0.00027021358255296946, Y_:tensor([2.9802, 5.0122], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0315], requires_grad=True), a_grad:tensor([0.0047]), a_grad_manual: 0.0047\n",
            " b:tensor([0.9490], requires_grad=True), b_grad:tensor([-0.0076]), b_grad_manual: -0.0076\n",
            "step: 87, loss:0.0002623923937790096, Y_:tensor([2.9805, 5.0120], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0311], requires_grad=True), a_grad:tensor([0.0046]), a_grad_manual: 0.0046\n",
            " b:tensor([0.9497], requires_grad=True), b_grad:tensor([-0.0074]), b_grad_manual: -0.0074\n",
            "step: 88, loss:0.0002547875919844955, Y_:tensor([2.9808, 5.0119], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0306], requires_grad=True), a_grad:tensor([0.0045]), a_grad_manual: 0.0045\n",
            " b:tensor([0.9505], requires_grad=True), b_grad:tensor([-0.0073]), b_grad_manual: -0.0073\n",
            "step: 89, loss:0.00024740712251514196, Y_:tensor([2.9811, 5.0117], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0302], requires_grad=True), a_grad:tensor([0.0045]), a_grad_manual: 0.0045\n",
            " b:tensor([0.9512], requires_grad=True), b_grad:tensor([-0.0072]), b_grad_manual: -0.0072\n",
            "step: 90, loss:0.0002402447280474007, Y_:tensor([2.9814, 5.0115], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0297], requires_grad=True), a_grad:tensor([0.0044]), a_grad_manual: 0.0044\n",
            " b:tensor([0.9519], requires_grad=True), b_grad:tensor([-0.0071]), b_grad_manual: -0.0071\n",
            "step: 91, loss:0.00023327927920036018, Y_:tensor([2.9816, 5.0114], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0293], requires_grad=True), a_grad:tensor([0.0043]), a_grad_manual: 0.0043\n",
            " b:tensor([0.9526], requires_grad=True), b_grad:tensor([-0.0070]), b_grad_manual: -0.0070\n",
            "step: 92, loss:0.00022652601182926446, Y_:tensor([2.9819, 5.0112], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0289], requires_grad=True), a_grad:tensor([0.0043]), a_grad_manual: 0.0043\n",
            " b:tensor([0.9533], requires_grad=True), b_grad:tensor([-0.0069]), b_grad_manual: -0.0069\n",
            "step: 93, loss:0.00021996101713739336, Y_:tensor([2.9822, 5.0110], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0284], requires_grad=True), a_grad:tensor([0.0042]), a_grad_manual: 0.0042\n",
            " b:tensor([0.9540], requires_grad=True), b_grad:tensor([-0.0068]), b_grad_manual: -0.0068\n",
            "step: 94, loss:0.00021359487436711788, Y_:tensor([2.9824, 5.0109], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0280], requires_grad=True), a_grad:tensor([0.0042]), a_grad_manual: 0.0042\n",
            " b:tensor([0.9546], requires_grad=True), b_grad:tensor([-0.0067]), b_grad_manual: -0.0067\n",
            "step: 95, loss:0.00020740462059620768, Y_:tensor([2.9827, 5.0107], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0276], requires_grad=True), a_grad:tensor([0.0041]), a_grad_manual: 0.0041\n",
            " b:tensor([0.9553], requires_grad=True), b_grad:tensor([-0.0066]), b_grad_manual: -0.0066\n",
            "step: 96, loss:0.0002013966004597023, Y_:tensor([2.9829, 5.0106], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0272], requires_grad=True), a_grad:tensor([0.0040]), a_grad_manual: 0.0040\n",
            " b:tensor([0.9560], requires_grad=True), b_grad:tensor([-0.0065]), b_grad_manual: -0.0065\n",
            "step: 97, loss:0.00019555992912501097, Y_:tensor([2.9832, 5.0104], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0268], requires_grad=True), a_grad:tensor([0.0040]), a_grad_manual: 0.0040\n",
            " b:tensor([0.9566], requires_grad=True), b_grad:tensor([-0.0064]), b_grad_manual: -0.0064\n",
            "step: 98, loss:0.00018989862292073667, Y_:tensor([2.9834, 5.0102], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0264], requires_grad=True), a_grad:tensor([0.0039]), a_grad_manual: 0.0039\n",
            " b:tensor([0.9572], requires_grad=True), b_grad:tensor([-0.0063]), b_grad_manual: -0.0063\n",
            "step: 99, loss:0.00018439721316099167, Y_:tensor([2.9837, 5.0101], grad_fn=<AddBackward0>)\n",
            "a:tensor([2.0260], requires_grad=True), a_grad:tensor([0.0039]), a_grad_manual: 0.0039\n",
            " b:tensor([0.9579], requires_grad=True), b_grad:tensor([-0.0062]), b_grad_manual: -0.0062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 pt_logreg.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igPwyzBqNEJx",
        "outputId": "4c49e153-281f-41b2-9452-f4fb8d048158"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss 1.677825692339311\n",
            "iteration 1000: loss 0.08812137120208574\n",
            "iteration 2000: loss 0.08132796013957298\n",
            "iteration 3000: loss 0.07779480319506155\n",
            "iteration 4000: loss 0.07550351835010251\n",
            "iteration 5000: loss 0.07382796197697139\n",
            "iteration 6000: loss 0.07251144907986762\n",
            "[(0.97, 0.9603960396039604), (0.96, 0.9795918367346939), (1.0, 0.9900990099009901)] [[ 97   2   1]\n",
            " [  4  96   0]\n",
            " [  0   0 100]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 pt_deep.py # data 4,2,40 i nn 2,2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8MQasxcOofo",
        "outputId": "86957104-b216-463a-ff29-8c5dbed9cbc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss 0.7085322737693787\n",
            "iteration 1000: loss 0.5561569929122925\n",
            "iteration 2000: loss 0.5397718548774719\n",
            "iteration 3000: loss 0.516151487827301\n",
            "iteration 4000: loss 0.5093638300895691\n",
            "iteration 5000: loss 0.5050562620162964\n",
            "iteration 6000: loss 0.5005543828010559\n",
            "iteration 7000: loss 0.4954639971256256\n",
            "iteration 8000: loss 0.4938802719116211\n",
            "iteration 9000: loss 0.49276405572891235\n",
            "iteration 10000: loss 0.4918145537376404\n",
            "recall:[(0.8875, 0.7634408602150538), (0.725, 0.8656716417910447)]\n",
            "precision: [[71  9]\n",
            " [22 58]]\n",
            "accuracy: 0.80625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 pt_deep.py # data 4,2,40 i nn 2,10,2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esgw4S9SP-Nl",
        "outputId": "fca38f6c-26c1-4b99-f0f3-1a00e7c5c9c9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss 1.8447242975234985\n",
            "iteration 1000: loss 0.44838887453079224\n",
            "iteration 2000: loss 0.44191694259643555\n",
            "iteration 3000: loss 0.439502090215683\n",
            "iteration 4000: loss 0.4377194941043854\n",
            "iteration 5000: loss 0.4360786974430084\n",
            "iteration 6000: loss 0.4348193109035492\n",
            "iteration 7000: loss 0.4338065981864929\n",
            "iteration 8000: loss 0.43284493684768677\n",
            "iteration 9000: loss 0.4319119453430176\n",
            "iteration 10000: loss 0.4311864972114563\n",
            "recall:[(0.975, 0.8387096774193549), (0.8125, 0.9701492537313433)]\n",
            "precision: [[78  2]\n",
            " [15 65]]\n",
            "accuracy: 0.89375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 pt_deep.py # data 4,2,40 i nn 2,10,10,2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb9JMSEvQWPr",
        "outputId": "508e25a2-f56f-4092-b771-bcbf7d5e42a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss 9.569859504699707\n",
            "iteration 1000: loss 0.2695121169090271\n",
            "iteration 2000: loss 0.23024551570415497\n",
            "iteration 3000: loss 0.2169807404279709\n",
            "iteration 4000: loss 0.20975545048713684\n",
            "iteration 5000: loss 0.20625510811805725\n",
            "iteration 6000: loss 0.1577834188938141\n",
            "iteration 7000: loss 0.151149719953537\n",
            "iteration 8000: loss 0.1482793241739273\n",
            "iteration 9000: loss 0.14646214246749878\n",
            "iteration 10000: loss 0.14487071335315704\n",
            "recall:[(0.9625, 0.9390243902439024), (0.9375, 0.9615384615384616)]\n",
            "precision: [[77  3]\n",
            " [ 5 75]]\n",
            "accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 pt_deep.py # data 6,2,10 i nn 2,2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuGfLnWWQeda",
        "outputId": "3c2c5e41-6705-4e15-efb2-f60269925d19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss 1.458279013633728\n",
            "iteration 1000: loss 0.5678195357322693\n",
            "iteration 2000: loss 0.5414180755615234\n",
            "iteration 3000: loss 0.530247151851654\n",
            "iteration 4000: loss 0.5240134000778198\n",
            "iteration 5000: loss 0.5196540355682373\n",
            "iteration 6000: loss 0.5149585008621216\n",
            "iteration 7000: loss 0.5115464329719543\n",
            "iteration 8000: loss 0.5087001323699951\n",
            "iteration 9000: loss 0.5063870549201965\n",
            "iteration 10000: loss 0.5048836469650269\n",
            "recall:[(0.9333333333333333, 0.6363636363636364), (0.4666666666666667, 0.875)]\n",
            "precision: [[28  2]\n",
            " [16 14]]\n",
            "accuracy: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 pt_deep.py # data 6,2,10 i nn 2,10,2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIUzdPhrQ7LK",
        "outputId": "764c3a83-418f-42bd-f2f1-761ac91877b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss 8.707029342651367\n",
            "iteration 1000: loss 0.5777360796928406\n",
            "iteration 2000: loss 0.5521997809410095\n",
            "iteration 3000: loss 0.5005514025688171\n",
            "iteration 4000: loss 0.4959138035774231\n",
            "iteration 5000: loss 0.4900909662246704\n",
            "iteration 6000: loss 0.48911893367767334\n",
            "iteration 7000: loss 0.4882875680923462\n",
            "iteration 8000: loss 0.48812976479530334\n",
            "iteration 9000: loss 0.48811835050582886\n",
            "iteration 10000: loss 0.48760560154914856\n",
            "recall:[(1.0, 0.6), (0.3333333333333333, 1.0)]\n",
            "precision: [[30  0]\n",
            " [20 10]]\n",
            "accuracy: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ksvm_wrap.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y72y6fqMTBlW",
        "outputId": "c108c77e-b0d5-4047-d2f5-aecfe285d674"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:[(1.0, 0.8823529411764706), (0.8666666666666667, 1.0)]\n",
            "precision: [[30  0]\n",
            " [ 4 26]]\n",
            "accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 mnist_shootout.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItHKclBLU5q0",
        "outputId": "756a6515-c93f-45fe-c693-aa54f62a6f78"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "60000 784 10\n",
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([10000, 28, 28])\n",
            "iteration 0: loss 7.5960373878479\n",
            "iteration 1000: loss 1.8547776937484741\n",
            "iteration 2000: loss 1.6549408435821533\n",
            "iteration 3000: loss 1.5554481744766235\n",
            "iteration 4000: loss 1.471063494682312\n",
            "[(0.9693877551020408, 0.1754710011082379), (0.9154185022026432, 0.9066317626527051), (0.001937984496124031, 0.3333333333333333), (0.804950495049505, 0.8017751479289941), (0.8289205702647657, 0.7941463414634147), (0.28699551569506726, 0.6632124352331606), (0.05010438413361169, 0.676056338028169), (0.0, 0.0), (0.002053388090349076, 0.2222222222222222), (0.707631318136769, 0.7710583153347732)]\n",
            "[[ 950    1    1    2    0   23    2    0    0    1]\n",
            " [  87 1039    0    4    2    2    1    0    0    0]\n",
            " [ 889   33    2   57   26    5   12    3    1    4]\n",
            " [ 161    1    0  813    1   20    2    0    0   12]\n",
            " [ 115    3    0    4  814    3    1    0    0   42]\n",
            " [ 498   17    2   68   34  256    1    0    2   14]\n",
            " [ 844    8    0    2   32    6   48    0    2   16]\n",
            " [ 830   17    1   22   30   22    1    0    2  103]\n",
            " [ 846   17    0   29   16   42    2    0    2   20]\n",
            " [ 194   10    0   13   70    7    1    0    0  714]]\n"
          ]
        }
      ]
    }
  ]
}